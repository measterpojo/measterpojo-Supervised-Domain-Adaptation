{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMGZMjCwY0ZtAtgEzE/056h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!apt-get install -qq git\n"],"metadata":{"id":"-lcfbP6hMJ-3","executionInfo":{"status":"ok","timestamp":1739666639531,"user_tz":360,"elapsed":2518,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","from getpass import getpass\n","\n","os.environ['GITHUB_USERNAME'] = getpass('GitHub username: ')\n","os.environ['GITHUB_TOKEN'] = getpass('GitHub token: ')\n","\n","!git config --global init.defaultBranch main\n","!git config --global user.email \"peterperez847@yahoo.com\"\n","!git config --global user.name \"measterpojo\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94Asa8mAOfML","executionInfo":{"status":"ok","timestamp":1739669429949,"user_tz":360,"elapsed":25464,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"c024f946-8f40-4cf4-f996-e5c9ff0fe59a"},"execution_count":23,"outputs":[{"name":"stdout","output_type":"stream","text":["GitHub username: ··········\n","GitHub token: ··········\n"]}]},{"cell_type":"code","source":["!git init\n","!echo \"# Supervised Domain Adaptation\" > README.md\n","!git add '/content/SupervisedDomainAdaptation.ipynb'\n","!git commit -m \"First commit\"\n","!git branch -M main\n","!git remote remove origin\n","!git remote add origin https://{os.environ['GITHUB_USERNAME']}:{os.environ['GITHUB_TOKEN']}@github.com/measterpojo/Supervised-Domain-Adaptation.git\n","!git push -u origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oFSAVmZsNhzt","executionInfo":{"status":"ok","timestamp":1739670031710,"user_tz":360,"elapsed":9185,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"75a69a3f-a92c-44e0-da6e-2a2488391066"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Reinitialized existing Git repository in /content/.git/\n","fatal: pathspec '/content/SupervisedDomainAdaptation.ipynb' did not match any files\n","On branch main\n","nothing to commit, working tree clean\n","Enumerating objects: 31, done.\n","Counting objects: 100% (31/31), done.\n","Delta compression using up to 8 threads\n","Compressing objects: 100% (23/23), done.\n","Writing objects: 100% (31/31), 8.42 MiB | 2.45 MiB/s, done.\n","Total 31 (delta 4), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (4/4), done.\u001b[K\n","To https://github.com/measterpojo/Supervised-Domain-Adaptation.git\n"," * [new branch]      main -> main\n","Branch 'main' set up to track remote branch 'main' from 'origin'.\n"]}]},{"cell_type":"markdown","source":["# **Introduction**"],"metadata":{"id":"DVEwgJa2Srxd"}},{"cell_type":"markdown","source":["Weakly Supervised Domain Adaptation (WSDA) is an exciting area of research that aims to improve the performance of machine learning models when there is a lack of fully labeled data in the target domain. Here are some key points and recent advancements in this field:\n"],"metadata":{"id":"88p8UFYDTG6h"}},{"cell_type":"markdown","source":["\n","\n","1.   Domain adaptation - The process of transferring knowledge from a source domain to a target domain\n","2.   Weak adaptation - Using weak labels, such as noisy or incomplete annotations to train models\n","\n"],"metadata":{"id":"cSCJF7wITnkc"}},{"cell_type":"markdown","source":["**Domain-Adversarial Neural Networks (DANN)**"],"metadata":{"id":"7FqBqzbGkQBY"}},{"cell_type":"markdown","source":["Domain-Adversarial Neural Networks (DANN) can be adapted for weakly supervised. DANN is a popular approach for domain adaptation that uses adversarial training to align feature distributions between the source and target domains. Here's a brief overview of how DANN can be applied in weakly supervised settings:"],"metadata":{"id":"CVOTJOTikAuH"}},{"cell_type":"markdown","source":["\n","\n","1.   Feature Extractor: Extracts features from the input data.\n","2.   Label Predictor: Predicts labels based on the extracted features.\n","3.   Domain Classifier: Predicts the domain of the input data (source or target).\n","\n"],"metadata":{"id":"qhjgJbIjmPzO"}},{"cell_type":"markdown","source":["**Applications**"],"metadata":{"id":"J1iwvzcUV5dm"}},{"cell_type":"markdown","source":["Semantic Segmentation  - Improving the accuracy of segmenting images into meaningful parts using weak labels.\n","\n"," Object Detection - Enhancing object detection models in target domains with limited annotations."],"metadata":{"id":"4NcEDtgSVaTP"}},{"cell_type":"markdown","source":["**Datasets**"],"metadata":{"id":"3W7VOo_-p7hI"}},{"cell_type":"markdown","source":["**Office-31** : The Office-31 dataset consists of 31 object categories commonly found in office settings. This dataset includes images from three domains. In this experiment we are only going to use 2 out of the 3\n","*   DSLR (Source)\n","*   Webcam (Target)\n","\n"],"metadata":{"id":"LuyMKb0Vp-2D"}},{"cell_type":"markdown","source":["# **Prerequisites**"],"metadata":{"id":"OvU9B5OxjOAA"}},{"cell_type":"markdown","source":["\n","\n","1.   Basic Knowledge of Machine Learning:\n","2.   Understanding of Domain Adaptation:\n","3.   Deep Learning Frameworks (PyTorch):\n","4.   Handling Weak Supervision:\n"],"metadata":{"id":"fBBRu8mfjT6M"}},{"cell_type":"markdown","source":["# **Code**"],"metadata":{"id":"xjXSmW6MloZO"}},{"cell_type":"markdown","source":["**Imports**"],"metadata":{"id":"EFxZQqPDop45"}},{"cell_type":"code","source":["import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torchvision\n","from torchvision import transforms\n","\n","\n","import kagglehub\n","\n","from PIL import Image\n","\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"],"metadata":{"id":"nkEPB-Y0rYJa","executionInfo":{"status":"ok","timestamp":1739665917605,"user_tz":360,"elapsed":10045,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Setup device-agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"KZrX_USkwEdt","executionInfo":{"status":"ok","timestamp":1739665917605,"user_tz":360,"elapsed":6,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"64d6e95f-3a62-4418-ebae-4e452586edf2"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["**Data Preparation**"],"metadata":{"id":"wK_MaaBnoxVE"}},{"cell_type":"code","source":["\n","# Download latest version\n","path = kagglehub.dataset_download(\"xixuhu/office31\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O70nJ-Hwt-5w","executionInfo":{"status":"ok","timestamp":1739665925909,"user_tz":360,"elapsed":8308,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"bfeb4e78-b296-40e4-d3aa-5351192a35e5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n","Downloading from https://www.kaggle.com/api/v1/datasets/download/xixuhu/office31?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 75.9M/75.9M [00:04<00:00, 18.1MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/xixuhu/office31/versions/1\n"]}]},{"cell_type":"code","source":["import os\n","\n","# walks through the dataset paths returning its contents\n","def walk_through_dir(dir_path):\n","  for dirpath, dirnames, filenames in os.walk(dir_path):\n","    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n","\n","# walk_through_dir(path)"],"metadata":{"collapsed":true,"id":"tGz8400cwLe8","executionInfo":{"status":"ok","timestamp":1739665925909,"user_tz":360,"elapsed":9,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Define transformations\n","simple_transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","])"],"metadata":{"id":"dNFCO8Up8GbF","executionInfo":{"status":"ok","timestamp":1739665925909,"user_tz":360,"elapsed":8,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["source_dir='/root/.cache/kagglehub/datasets/xixuhu/office31/versions/1/Office-31/dslr'\n","target_dir='/root/.cache/kagglehub/datasets/xixuhu/office31/versions/1/Office-31/webcam'"],"metadata":{"id":"mlNl5wyq9hdf","executionInfo":{"status":"ok","timestamp":1739665925910,"user_tz":360,"elapsed":9,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from genericpath import isdir\n","#Custom Dataset\n","class CustomDataset(Dataset):\n","  def __init__(self, root_dir, transform=None) -> None:\n","      super().__init__()\n","      self.root_dir = root_dir\n","      self.transform = transform\n","      self.image_paths = []\n","      self.labels = []\n","      self.label_to_idx = {}\n","      self._prepare_dataset()\n","\n","  def _prepare_dataset(self):\n","      for idx, label_dir in enumerate(os.listdir(self.root_dir)):\n","          label_path = os.path.join(self.root_dir, label_dir)\n","          if os.path.isdir(label_path):\n","              self.label_to_idx[label_dir] = idx\n","              for image_name in os.listdir(label_path):\n","                  image_path = os.path.join(label_path, image_name)\n","                  if os.path.isfile(image_path):\n","                      self.image_paths.append(image_path)\n","                      self.labels.append(self.label_to_idx[label_dir])\n","\n","  def __len__(self):\n","    return len(self.image_paths)\n","\n","  def __getitem__(self, index):\n","    img_path = self.image_paths[index]\n","    image = Image.open(img_path).convert('RGB')\n","    label = self.labels[index]\n","\n","    if self.transform:\n","      image = self.transform(image)\n","\n","    return image, torch.tensor(label)"],"metadata":{"id":"Avv7Gf0Cze95","executionInfo":{"status":"ok","timestamp":1739665925910,"user_tz":360,"elapsed":9,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["source_dataset = CustomDataset(source_dir, simple_transform)\n","target_dataset = CustomDataset(target_dir, simple_transform)\n","\n","source_dataloader = DataLoader(source_dataset, batch_size=32, shuffle=True, drop_last=True)\n","target_dataloader = DataLoader(target_dataset, batch_size=32, shuffle=True, drop_last=True)"],"metadata":{"id":"tE4DJCNm_qVD","executionInfo":{"status":"ok","timestamp":1739665925910,"user_tz":360,"elapsed":8,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["len(source_dataloader), len(target_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0LvQTiMDmnOE","executionInfo":{"status":"ok","timestamp":1739665925910,"user_tz":360,"elapsed":8,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}},"outputId":"83048588-260a-4c93-9c64-132d21765517"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15, 24)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["for source_batch, target_batch in zip(source_dataloader, target_dataloader):\n","\n","    source_data, source_labels = source_batch"],"metadata":{"collapsed":true,"id":"586F4pvZmhV8","executionInfo":{"status":"ok","timestamp":1739665933592,"user_tz":360,"elapsed":7688,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# for batch in source_dataloader:\n","#     print(batch)\n","#     break"],"metadata":{"id":"TTPTHjZ8n0ec","executionInfo":{"status":"ok","timestamp":1739665933593,"user_tz":360,"elapsed":9,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["**Models**"],"metadata":{"id":"EinNiYFrojco"}},{"cell_type":"markdown","source":["**Model Architecture:**\n","We constructed three key components: the FeatureExtractor, LabelPredictor, and DomainClassifier.\n","\n","The FeatureExtractor learns domain-invariant features, while the LabelPredictor performs classification tasks.\n","\n","The DomainClassifier discriminates between source and target domains, helping the FeatureExtractor align features from both domains."],"metadata":{"id":"eS0Eb2QwJ5Os"}},{"cell_type":"code","source":["class FeatureExtractor(nn.Module):\n","    def __init__(self):\n","        super(FeatureExtractor, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.fc1 = nn.Linear(64 * 252 * 252, 128)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        return x\n","\n","class LabelPredictor(nn.Module):\n","    def __init__(self):\n","        super(LabelPredictor, self).__init__()\n","        self.fc1 = nn.Linear(128, 31)\n","\n","    def forward(self, x):\n","        return self.fc1(x)\n","\n","class DomainClassifier(nn.Module):\n","    def __init__(self):\n","        super(DomainClassifier, self).__init__()\n","        self.fc1 = nn.Linear(128, 2)\n","\n","    def forward(self, x):\n","        return self.fc1(x)"],"metadata":{"id":"4W2Xe9E0rsYK","executionInfo":{"status":"ok","timestamp":1739665933594,"user_tz":360,"elapsed":8,"user":{"displayName":"Peter Perez","userId":"12102864046237915346"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["**Training Loop**"],"metadata":{"id":"XIR7QXtOo3gj"}},{"cell_type":"code","source":["num_epochs = 10\n","\n","torch.autograd.set_detect_anomaly(True)\n","\n","def train_dann(num_epochs, source_loader, target_loader):\n","  feature_extractor = FeatureExtractor().to(device)\n","  label_predictor = LabelPredictor().to(device)\n","  domain_classifier = DomainClassifier().to(device)\n","\n","  optimizer_fe = optim.Adam(feature_extractor.parameters(), lr=0.001)\n","  optimizer_lp = optim.Adam(label_predictor.parameters(), lr=0.001)\n","  optimizer_dc = optim.Adam(domain_classifier.parameters(), lr=0.001)\n","\n","  loss_fn = nn.CrossEntropyLoss()\n","\n","  for epoch in range(num_epochs):\n","    for source_batch, target_batch in zip(source_loader, target_loader):\n","      source_data, source_labels = source_batch\n","      target_data, _ = target_batch\n","\n","      # print(source_labels)\n","\n","      source_data = source_data.to(device)\n","      source_labels = source_labels.to(device)\n","      target_data = target_data.to(device)\n","\n","      # Train label predictor on source data\n","      optimizer_fe.zero_grad()\n","      optimizer_lp.zero_grad()\n","\n","      source_feature = feature_extractor(source_data)\n","      source_predictions = label_predictor(source_feature)\n","      loss_lp = loss_fn(source_predictions, source_labels)\n","      loss_lp.backward(retain_graph=True)\n","      optimizer_fe.step()\n","      optimizer_lp.step()\n","\n","      # train domain classifier\n","      optimizer_dc.zero_grad()\n","      source_domain_labels = torch.zeros(source_data.size(0)).long().to(device)\n","      target_domain_labels = torch.ones(target_data.size(0)).long().to(device)\n","      domain_labels = torch.cat([source_domain_labels, target_domain_labels], 0)\n","\n","      with torch.no_grad():\n","        target_feature = feature_extractor(target_data)\n","      all_features = torch.cat([source_feature.detach(), target_feature.detach()], 0)\n","      domain_predictions = domain_classifier(all_features)\n","      loss_dc = loss_fn(domain_predictions, domain_labels)\n","      loss_dc.backward()\n","      optimizer_dc.step()\n","\n","      # train feature extractor to fool domain classifier\n","      optimizer_fe.zero_grad()\n","      source_feature = source_feature.detach()  # Ensure the features are detached here\n","      target_feature = target_feature.detach()  # Ensure the features are detached here\n","      all_features = torch.cat([source_feature, target_feature], 0)\n","      domain_predictions = domain_classifier(all_features)\n","      loss_adv = loss_fn(domain_predictions, domain_labels)\n","      loss_adv.backward(retain_graph=True)\n","      optimizer_fe.step()\n","  print(f\"Epoch {epoch+1}/{num_epochs}, Label Loss: {loss_lp.item():.4f}, Domain Loss: {loss_dc.item():.4f}\")\n","\n","# Assuming we have data loaders `source_loader` and `target_loader`\n","train_dann(num_epochs=50, source_loader=source_dataloader, target_loader=target_dataloader)"],"metadata":{"id":"zYTNWmDvDAN5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"6tQtCfcuqXR-"}},{"cell_type":"markdown","source":["In this tutorial, we explored the implementation of Domain-Adversarial Neural Networks (DANN) using the Office-31 dataset."],"metadata":{"id":"IhokZlUnJjvg"}}]}